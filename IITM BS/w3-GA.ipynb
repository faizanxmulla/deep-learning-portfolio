{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Importing Libraries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Loading Parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('parameters.npz') as params:\n",
    "    W1, W2, W3 = params['W1'], params['W2'], params['W3']\n",
    "    b1, b2, b3 = params['b1'], params['b2'], params['b3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1, 0, 1]).reshape(-1, 1)\n",
    "y = np.array([0, 0, 1]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Defining Functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax function.\n",
    "\n",
    "def softmax(x):\n",
    "    y = np.exp(x)\n",
    "    return y / np.sum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q1 : **How many (learnable) parameters are there in the network?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x.size for x in [W1, W2, W3, b1, b2, b3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q2 : **What is the sum of the elments of output a<sub>1</sub>? (Choose the nearest option to your answer)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.5350184 ]\n",
      " [1.98250233]\n",
      " [1.93014489]]\n"
     ]
    }
   ],
   "source": [
    "a1 = (W1 @ X) + b1\n",
    "print(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.44766562448759"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q3 : **What is the sum of the elments of output h<sub>1</sub>? (Choose the nearest option to your answer)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.82273938]\n",
      " [0.87894766]\n",
      " [0.87326546]]\n"
     ]
    }
   ],
   "source": [
    "h1 = sigmoid(a1)\n",
    "print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5749524957231924"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q4 : **The sum of the elements of [a<sub>2</sub>, h<sub>2</sub>, a<sub>3</sub>]. What is the loss value?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, calculate the remaining entities i.e. a<sub>2</sub>, h<sub>2</sub> & a<sub>3</sub> & also y_hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = W2 @ h1 + b2\n",
    "h2 = sigmoid(a2)\n",
    "a3 = W3 @ h2 + b3\n",
    "\n",
    "y_hat = softmax(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.460166773282592, 2.63139309587371, 4.874920988265703]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a2.sum(), h2.sum(), a3.sum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23691422],\n",
       "       [0.33838847],\n",
       "       [0.42469732]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8563785622753882\n"
     ]
    }
   ],
   "source": [
    "loss_value = -1 * np.sum(y * np.log(y_hat))\n",
    "print(loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Backpropagation Formulas for reference** : \n",
    "\n",
    "1. ∇<sub>a<sub>L</sub></sub>L(θ) = - (e(y) - ŷ)\n",
    "\n",
    "2. ∇<sub>W<sub>k</sub></sub>L(θ) = ∇<sub>a<sub>k</sub></sub>L(θ) . h<sub>k-1</sub><sup>T</sup>\n",
    "\n",
    "3. ∇<sub>b<sub>k</sub></sub>L(θ) = ∇<sub>a<sub>k</sub></sub>L(θ)\n",
    "\n",
    "4. ∇<sub>h<sub>k-1</sub></sub>L(θ) = W<sub>k</sub><sup>T</sup> . ∇<sub>a<sub>k</sub></sub>L(θ)\n",
    "\n",
    "5. ∇<sub>a<sub>k-1</sub></sub>L(θ) = ∇<sub>h<sub>k-1</sub></sub>L(θ) ⊙ [..., g'(a<sub>k-1 ,j</sub>), ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q5 : **Choose the vector that corresponds to : ∇<sub>a<sub>3</sub></sub>L(θ).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is aka \"gradient of loss function wrt a<sub>3</sub>\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.23691422]\n",
      " [ 0.33838847]\n",
      " [-0.57530268]]\n"
     ]
    }
   ],
   "source": [
    "gradient_a3 = -(y - y_hat)\n",
    "print(gradient_a3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q6 : **We know that after computing gradients, we update the values of b<sub>2</sub> by subtracting its gradient, as shown below :**\n",
    "\n",
    "b<sub>2</sub> - η∇<sub>b<sub>2</sub></sub>L(θ). \n",
    "\n",
    "**Which of the following is the gradient vector of : b<sub>2</sub> ??**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21202113  0.18529411  0.2260992 ]\n",
      " [ 0.30283325  0.26465862  0.3229412 ]\n",
      " [-0.51485438 -0.44995274 -0.5490404 ]]\n"
     ]
    }
   ],
   "source": [
    "gradient_w3 = gradient_a3 @ h2.T\n",
    "print(gradient_w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21202113  0.18529411  0.2260992 ]\n",
      " [ 0.30283325  0.26465862  0.3229412 ]\n",
      " [-0.51485438 -0.44995274 -0.5490404 ]]\n"
     ]
    }
   ],
   "source": [
    "gradient_b3 = gradient_w3\n",
    "print(gradient_b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1954864 ]\n",
      " [-0.11722488]\n",
      " [-0.08814526]]\n"
     ]
    }
   ],
   "source": [
    "gradient_h2 = W3.T @ gradient_a3\n",
    "print(gradient_h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01838198]\n",
      " [-0.01997644]\n",
      " [-0.0038401 ]]\n"
     ]
    }
   ],
   "source": [
    "gradient_a2 = gradient_b2 = gradient_h2 * sigmoid(a2) * (1 - sigmoid(a2))\n",
    "\n",
    "print(gradient_a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q7 : **Update all the parameters with the calculated gradients. Forward propagate the input through the network. What is the new loss value ?** (Take η=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue calculating / updating parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01512358  0.0161568   0.01605235]\n",
      " [-0.0164354  -0.01755824 -0.01744473]\n",
      " [-0.0031594  -0.00337525 -0.00335343]]\n"
     ]
    }
   ],
   "source": [
    "gradient_w2 = gradient_a2 @ h1.T\n",
    "print(gradient_w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00571305]\n",
      " [ 0.01326947]\n",
      " [-0.01908499]]\n"
     ]
    }
   ],
   "source": [
    "gradient_h1 = W2.T @ gradient_a2\n",
    "print(gradient_h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00083319]\n",
      " [ 0.00141185]\n",
      " [-0.00211219]]\n"
     ]
    }
   ],
   "source": [
    "gradient_a1 = gradient_b1 = gradient_h1 * (sigmoid(a1) * (1 - sigmoid(a1)))\n",
    "\n",
    "print(gradient_a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00083319  0.          0.00083319]\n",
      " [ 0.00141185  0.          0.00141185]\n",
      " [-0.00211219  0.         -0.00211219]]\n"
     ]
    }
   ],
   "source": [
    "gradient_w1 = gradient_a1 @ X.T\n",
    "print(gradient_w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, update all the parameters with the calculated gradients. \n",
    "\n",
    "Also, eta = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_new = W1 - eta * gradient_w1\n",
    "b1_new = b1 - eta * gradient_b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 :\n",
      " [[0.5488135  0.71518937 0.60276338]\n",
      " [0.54488318 0.4236548  0.64589411]\n",
      " [0.43758721 0.891773   0.96366276]]\n",
      "\n",
      "W1_new : \n",
      " [[0.54798032 0.71518937 0.60193019]\n",
      " [0.54347133 0.4236548  0.64448226]\n",
      " [0.4396994  0.891773   0.96577495]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"W1 :\\n {W1}\\n\")\n",
    "print(f\"W1_new : \\n {w1_new}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2_new = W2 - eta * gradient_w2\n",
    "b2_new = b2 - eta * gradient_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "w3_new = W3 - eta * gradient_w3\n",
    "b3_new = b3 - eta * gradient_b3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, forward propagating the input through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = w1_new @ X + b1_new\n",
    "h1 = sigmoid(a1)\n",
    "\n",
    "a2 = w2_new @ h1 + b2_new\n",
    "h2 = sigmoid(a2)\n",
    "\n",
    "a3 = w3_new @ h2 + b3_new\n",
    "y_hat = softmax(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03807969 0.03906752 0.92285279]\n"
     ]
    }
   ],
   "source": [
    "y_hat = np.sum(y_hat, axis=1)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New loss value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.590823679375906\n"
     ]
    }
   ],
   "source": [
    "loss_value_new = -1 * np.sum(y * np.log(y_hat))\n",
    "print(loss_value_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
